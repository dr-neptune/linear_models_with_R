
```{r}
library(tidyverse)
library(faraway)
library(magrittr)
library(broom)
library(gganimate)
```

# Diagnostics 

The estimation of and inference from the regression model depend on several assumptions. These assumptions should be checked using regression diagnostics before using the model in earnest. 

We can divide the problems into three categories: 

**Error** : we have assumed that our errors are independent, have equal variance, and are normally distributed. 

**Model** : we have assumed that the structural part of the model, $E[y] = X\beta$, is correct. 

**Unusual Observations** : Sometimes a few observations do not fit the model and they might change the choice and fit of the model. 

# Checking Error Assumptions

We wish to check for independence, constant variance, and normality of the errors. We can examine the residuals, $\hat{\epsilon}$.

Recall that $\hat{y} = X(X^TX)^{-1}XTy = Hy$ where $H$ is the hat matrix, so that 

<center>
$\hat{\epsilon} = y - \hat{y} = (I - H)y = (I - H)X\beta + (I - H)\epsilon = (I - H)\epsilon$
</center>

Therefore, var $\hat{\epsilon}$ = var $(I - H)\epsilon$ = $(I - H)\sigma^2$ assuming var ${\epsilon} = \sigma^2 I$. 

We see that while the errors may have equal variance and be uncorrelated, the residuals do not. Fortuneately, correlation of errors usually has little imact and can be applied to residuals in order to check the assumptions on the error. 

## Constant Variance 

We can not check the assumption of constant variance just by examining the residuals alone. We need to check whether the variance in the residuals is related to some other quantity. 

The most useful diagnostic is a plot of $\hat{\epsilon}$ against $\hat{y}$, or residuals against fitted. If all is well, we should see constant symmetrical variation (known as homoscedasticity) in the vertical $\hat{\epsilon}$ direction. **Nonconstant** variance is called heterscedasticity. Nonlinearity of the structural part of the model can also be detected in this plot. 

It is also worthwhile to plot $\hat{\epsilon}$ against $x_i$ for potential predictors that are in the current model as well as those that are not used. For plots of residuals against predictors that are not in the model, any observed structure may indicate that this predictor should be included in the model. 

```{r}
data(savings, package = "faraway")
savings %<>% as_tibble()

(lmod <- lm(sr ~ ., savings))

lm_aug <- lmod %>% augment()

diag_plot <- function(data, x, y) {
    data %>%
        ggplot(aes(x = {{x}}, y = {{y}})) +
        geom_point() +
        geom_hline(yintercept = 0, lty = 2, alpha = 0.5)
}

lm_aug %>%
    diag_plot(x = .fitted, y = .resid)
```

The plot above shows that there likely no heteroscedasticity, or nonconstant variance in the error. We can examine the constant variance more closely by plotting $\sqrt{|\hat{\epsilon}|}$ against $\hat{y}$. Considering the absolute value of the residuals roughly doubles the resolution. For truly normal errors, $|\hat{\epsilon}|$ would follow what is known as a half normal distribution (since it has a density which is simply the upper half of a normal density). Such a distribution is quite skewed, and the skewness can be reduced by the square root transformation.

```{r}
lm_aug %>%
    diag_plot(x = .fitted, y = sqrt(abs(.resid)))
```

We see approximately constant variation in the plot above. 

We can also perform a numerical test to check nonconstant variance

```{r}
lm(sqrt(abs(.resid)) ~ .fitted, lm_aug) %>% summary()
```

This test checks for a linear trend in the variation. As a result, it might be good at detecting a particular kind of nonconstant variance, but have no power to detect another (think Simpson's paradox). Residual plots are generally more versatile here because unanticipated problems may be spotted.

It is often hard to judge residual plots. Here are four plots which show:

1. Constant Variance 
2. Strong Nonconstant Variance 
3. Mild Nonconstant Variance 
4. Nonlinearity 

```{r}
map(seq_len(10), ~ tibble("x" = runif(100),
                          "a" = rnorm(100),
                          "b" = x * rnorm(100),
                          "c" = sqrt(x) * rnorm(100),
                          "d" = cos(x * pi / 25) +
                              rcauchy(n = 100, location = 5, scale = 5),
                          "gen_group" = .x)) %>%
    bind_rows() -> resid_gen

animate_resids <- function(data, x, y, title) {
    data %>%
        diag_plot(x = {{x}}, y = {{y}}) +
        ggtitle(as.character(title)) +
        transition_states(
            gen_group,
            transition_length = 10,
            state_length = 1) +
        enter_fade() +
        exit_shrink()
}

resid_gen %>%
    animate_resids(x = x, y = a, title = "Constant Variance") -> p1g

resid_gen %>%
    diag_plot(x, a) +
    ggtitle("Constant Variance") -> p1

resid_gen %>%
    animate_resids(x = x, y = b, title = "Strong Nonconstant Variance") -> p2g

resid_gen %>%
    diag_plot(x, b) +
    ggtitle("Strong Nonconstant Variance") -> p2

resid_gen %>%
    animate_resids(x = x, y = c, title = "Mild Nonconstant Variance") -> p3g

resid_gen %>%
    diag_plot(x, c) +
    ggtitle("Mild Nonconstant Variance") -> p3

resid_gen %>%
    animate_resids(x = x, y = d, title = "Nonlinearity") -> p4g

resid_gen %>%
    diag_plot(x, d) +
    ggtitle("Nonlinearity") -> p4

cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)

list("constant_var" = p1g, "strong_nonconstant_var" = p2g,
     "mild_nonconstant_var" = p3g, "nonlinearity" = p4g) %>%
    imap(., ~ anim_save(path = getwd(),
                       filename = paste0(.y, ".gif"),
                       animation = .x))
```

Now we can look at some residuals against predictor plots for the savings data 

```{r}
resid_plots <- with(lm_aug, list("pop15" = pop15, "pop75" = pop75,
                  "dpi" = dpi, "ddpi" = ddpi)) %>%
    imap(., ~ lm_aug %>% diag_plot(x = .x, y = .resid) +
        xlab(.y) + ylab("residuals"))

cowplot::plot_grid(plotlist = resid_plots, ncol = 2)
```

In the first plot, for population under 15, we can see two groups. We can compare and test the variances in these groups. 

Given two independent samples from normal distributions, we can test for equal variance using the test statistic of the ratio of the two variances. The null distribution is an F with degrees of freedom given by the two samples

```{r}
var.test(lm_aug$.resid[lm_aug$pop15 > 35], lm_aug$.resid[lm_aug$pop15 <= 35])
```

We see that there is a significant difference with our p-value of 0.01358 and we fail to reject our alternative hypothesis that the true ratio of variances is not equal to 1. 

When problems are seen in the diagnostic plots, some modification of the model is suggested. 

- If some nonlinearity is observed, perhaps in conjunction with nonconstant variance, a transformation of the variables should be considered. 

- If the problem is solely one of nonconstant variance with no suggestion of nonlinearity, then the use of weighted least squares may be appropriate.

Alternatively, when non constant variance is seen in the plot of the residuals against fitted values, a transformation of the response y to h(y) where h() can be chosen so that var h(y) is constant should be considered. 

To see how to choose h: 

$h(y) = h(Ey) + (y - Ey)h'(Ey) + ...$
$var h(y) = 0 + h'(Ey)^2 var y + ...$
$h'(Ey) \propto (var y)^{-1/2}$
$h(y) = \int \frac{dy}{\sqrt{var y}} = \int \frac{dy}{SD(y)}$

For example, if $var y = var \epsilon \propto (Ey)^2$, then $h(y) = \log y$ is suggested, while if $var \epsilon \propto (Ey)$, then $h(y) = \sqrt{y}$

Sometimes it can be difficult to find a good transformation. For example when $y_i \leq 0$ for some $i$, square root or log transformations will fail. 

Consider the residuals vs fitted plot for the Galapagos data:

```{r}
data(gala, package = "faraway")
lmod <- lm(Species ~ Area + Elevation + Scruz + Nearest + Adjacent, gala)

(lmod %>% augment() %>%
    diag_plot(x = .fitted, y = .resid) -> p1)
```

The first plot has non constant variance (and evidence of nonlinearity). The square root transformation is often appropriate for count response data. The Poisson distribution is a good model for counts and that distribution has the property that the mean is equal to the variance, thus suggesting the square root transformation. 

```{r}
lmod <- lm(sqrt(Species) ~ Area + Elevation + Scruz + Nearest + Adjacent, gala)

(lmod %>% augment %>%
    diag_plot(x = .fitted, y = .resid) -> p2)
```

We see in the second plot that the variance is now constant and the signs of nonlinearity have gone. Our guess at a variance stabilizing transformation worked here, but we could have always tried something else 

```{r}
cowplot::plot_grid(p1, p2, ncol = 2)
```

# Normality 

The tests and confidence intervals we use are based on the assumption of normally distributed errors. The residuals can be assessed for normality using a QQ plot. This compares the residuals to ideal normal observations. 

```{r}
lmod <- lm(sr ~ pop15 + pop75 + dpi + ddpi, savings)

lmod %>%
    augment() %>%
    ggplot(aes(sample = .resid)) +
    stat_qq() +
    stat_qq_line() -> p1

lmod %>%
    augment() %>%
    ggplot(aes(x = .resid)) +
    geom_histogram(bins = 30, fill = "skyblue", color = "black") -> p2

cowplot::plot_grid(p1, p2, ncol = 1)
```

Normal residuals should follow the line approximately. The histogram should be the familiar bell shape. 

We can get an idea of the variation to be expected in QQ plots in the following simulation. We generate data from different distributions:

1. Normal 
2. Log-Normal (an example of a skewed distribution)
3. Cauchy (an example of a long tailed (leptokurtic) distribution)
4. Uniform (an example of a short tailed (platykurtic) distribution)

```{r}
map(seq_len(10), ~ tibble("x" = rnorm(100),
                          "a" = rnorm(100),
                          "b" = exp(rnorm(100)),
                          "c" = rcauchy(100),
                          "d" = runif(100),
                          "gen_group" = .x)) %>%
    bind_rows() -> resid_gen

qq_plot <- function(data, choice, title) {
    data %>%
        ggplot(aes(sample = {{choice}})) +
        stat_qq() +
        stat_qq_line() +
        ggtitle(title)
}

qq_plots <- with(resid_gen, list("Normal" = a,
                                 "Log-Normal | Skewed" = b,
                                 "Cauchy | Long-Tail" = c,
                                 "Uniform | Short-Tail" = d)) %>%
    imap(., ~ resid_gen %>%
         qq_plot(choice = .x, title = .y))

cowplot::plot_grid(plotlist = qq_plots, ncol = 2)
```


Sometimes extreme cases may be the sign of a long tailed error like the Cauchy distribution, or they can just be outliers. If removing outliers results in other points becoming more prominent in the plot, the problem is likely due to a long tail error.

When the errors are not normal, least squares estimates may not be optimal. They will still be the best linear unbiased estimates, but other robust estimators may be more effective. Tests and confidence intervals will not be exact, but we can still appeal to the central limit theorem to assert that intervals constructed will be increasingly accurate approximations for larger sample sizes. 

When non-normality is found, the resolution depends on the type of problem found:

- Short tailed distributions are not serious usually and can generally be ignored 
- Skewed errors may be ameliorated by a transformation 
- Long tailed errors may require us accepting non-normality and basing the inference on the assumption of another distribution or use resampling methods like the bootstrap or permutation tests. Alternatively, we can use robust methods which lend less weight to outliers but may again require resampling for the inference. 

A formal test for normality is the Shapiro-Wilk test:

```{r}
shapiro.test(residuals(lmod))
```

In this test, the null hypothesis is that the residuals are normal. In our case, we have a p-value of 0.8524 and thus we do not reject the null hypothesis. The p-value is not helpful as an indicator of what action to take, so it is reccommended to use this in conjunction with a QQ plot. 

# Correlated Errors

