* Problems with Error
:PROPERTIES:
:header-args: :session R-session :results output value :colnames yes
:END:

#+NAME: round-tbl
#+BEGIN_SRC emacs-lisp :var tbl="" fmt="%.1f"
(mapcar (lambda (row)
          (mapcar (lambda (cell)
                    (if (numberp cell)
                        (format fmt cell)
                      cell))
                  row))
        tbl)
#+end_src

#+RESULTS: round-tbl

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
library(tidyverse)
library(faraway)
library(broom)
library(magrittr)
#+END_SRC

#+RESULTS:
| x         |
|-----------|
| magrittr  |
| broom     |
| faraway   |
| forcats   |
| stringr   |
| dplyr     |
| purrr     |
| readr     |
| tidyr     |
| tibble    |
| ggplot2   |
| tidyverse |
| stats     |
| graphics  |
| grDevices |
| utils     |
| datasets  |
| methods   |
| base      |

We have assumed that the error $\epsilon$ is iid, and we have also assumed that the errors are normally distributed in order to carry out normal statistical inference. These assumptions can often be violated and we must consider alternatives.

- When the errors are dependent, we can use *generalized least squares*
- When the errors are independent, but not identically distributed, we can use weighted least squares
- When errors are not normally distributed, we can use *robust regression*

** Generalized Least Squares

We have assumed that $var \epsilon = \sigma^2 I$, but sometimes errors have nonconstant variance or are correlated. Suppose instead that $var \epsilon = \sigma^2 \Sigma$, where $\sigma^2$ is unknown but $\Sigma$ is known. In other words, we know the correlation and relative variance between the errors, but we do not know the absolute scale of the variation. 

We can write $\Sigma = SS^T$ where S is a triangular matrix using the Cholesky Decomposition (a sort of square root for a matrix). Then we can transform the regression model as follows:

$y = x\beta + \epsilon$
$S^{-1}y = S^{-1}X\beta + S^{-1}\epsilon$
$y' = X'\beta + \epsilon'$

Then our sum of squared error is 

#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-15 22:43:34
[[file:Problems with Error/screenshot_2020-02-15_22-43-34.png]]

#+DOWNLOADED: /tmp/screenshot.png @ 2020-02-15 22:44:04
[[file:Problems with Error/screenshot_2020-02-15_22-44-04.png]]

The main problem of GLS in practice is that $\Sigma$ may not be known and we have to estimate it. 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
data(globwarm, package = "faraway")
gwarm <- globwarm %>% as_tibble()

lmod <- lm(nhtemp ~ ., gwarm)

lmod %>% tidy()
#+END_SRC

#+RESULTS:
| term        | estimate | std.error | statistic |              p.value |
|-------------+----------+-----------+-----------+----------------------|
| (Intercept) |    -15.2 |       1.7 |      -8.8 | 4.34443093246517e-15 |
| wusa        |     -0.1 |       0.0 |      -3.2 |                  0.0 |
| jasper      |      0.0 |       0.1 |       0.2 |                  0.9 |
| westgreen   |      0.1 |       0.0 |       2.0 |                  0.0 |
| chesapeake  |      0.0 |       0.0 |       0.2 |                  0.8 |
| tornetrask  |      0.1 |       0.0 |       1.4 |                  0.2 |
| urals       |      0.1 |       0.1 |       1.2 |                  0.2 |
| mongolia    |     -0.2 |       0.0 |      -3.5 |                  0.0 |
| tasman      |      0.0 |       0.0 |       0.1 |                  0.9 |
| year        |      0.0 |       0.0 |       8.7 | 9.59662211186724e-15 |

Then we can check whether our errors are correlated. This data was collected over time, so its a very real possibility. We calculate this by computing the correlation between the vector of residuals with the first and then the last term omitted.

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
cor(residuals(lmod)[-1],
    residuals(lmod)[-length(residuals(lmod))])
#+END_SRC

#+RESULTS:
|   x |
|-----|
| 0.4 |

The simplest way to model this is the autoregressive form:

$\epsilon_{i+1} = \phi \epsilon_i + \delta_i$

where $\delta_i \sim N(0, \tau^2)$

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
library(nlme)

glmod <- gls(nhtemp ~ ., correlation = corAR1(form = ~year), na.omit(gwarm))

glmod %>% summary()
#+END_SRC

There are no -significant- predictors and the standard errors are rather large. However, there is substantial collinearity between the predictors, so this should not be interpreted as "no predictor effect".

We have a reasonably sized Phi estimate, which can expect as we would likely have carryover of temperature from one year to the next. 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
# check confidence intervals
intervals(glmod, which = "var-cov")
#+END_SRC

We see from the interval on Phi that our coefficient is far from 0 and shows significant positive correlation. 

For this example, we might investigate whether a more sophisticated model should apply to errors, perhaps an ARMA model. This can be implemented using the corARMA function. 

Another situation where correlation between errors might be anticipated is where observations are grouped in some way. For example, consider an experiment to compare eight varieties of oats. The growing area was heterogeneous and was grouped into 5 blocks. Each variety was sown once within each block and the yield in grams per 16 foot row were recorded. 

It is reasonable to expect that the errors are correlated (cor($\epsilon_i, \epsilon_j$)) is $\rho$ if i and j are in the same block and 0 otherwise. This is called the *compound symmetry* assumption and is modeled as follows:

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
glmod <- gls(yield ~ variety,
             data = oatvar,
             correlation = corCompSymm(form = ~1 | block))

intervals(glmod)
#+END_SRC

Our value of $\rho$ shows that there is a correlation around 0.4 between the errors within the blocks. 

** Weighted Least Squares

Sometimes the errors are uncorrelated, but have unequal variance where the form of the inequality is known. Weighted least squares is a special case of Generalized least squares that can be used in this case. 

Cases with low variability get a high weight, while those with high variability get a low weight. 

Some examples: 

#+DOWNLOADED: /tmp/screenshot.png @ 2020-03-03 20:14:46
[[file:Problems with Error/screenshot_2020-03-03_20-14-46.png]]


*** Example 

Elections for the French presidency proceed in two rounds. In 1981 there were 10 candidates in the first round, and the top two candidates went on to the second round. 

The losers in the first round can gain political favor by asking their supporters to vote for one of the two finalists. We wish to infer from the published vote totals how this transfer may have happened. 

 #+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
data(fpe, package = "faraway")
fpe %<>% as_tibble(rownames = "department")
fpe %>% head()
 #+END_SRC

A:K stand for the first round, and A2, B2 stand for the initial round victors (A and B were the first round victors). EI stands for the registered voters. The number of voters in the second round was higher than the first round, and the difference is denoted by N. 


#+DOWNLOADED: /tmp/screenshot.png @ 2020-03-03 20:24:32
[[file:Problems with Error/screenshot_2020-03-03_20-24-32.png]] 

If we treat the above as a regression equation, there will be some error from department to department. The error will have a variance in proportion to the number of voters because it will be like a variance of a sum rather than the variance of a mean. 

Since the weights should be inversely proportional to the variance, we should set the weights to 1 / EI. Notice this equation also has no intercept. 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
lmod <- lm(A2 ~ A + B + C + D + E + F + G + H + J + K + N - 1,
           fpe,
           weights = (1 / EI))

lmod %>% tidy()
#+END_SRC

#+RESULTS:
| term | estimate | std.error | statistic |              p.value |
|------+----------+-----------+-----------+----------------------|
| A    |      1.1 |       0.0 |      29.9 | 2.22469266213566e-13 |
| B    |     -0.1 |       0.0 |      -3.1 |                  0.0 |
| C    |      0.2 |       0.1 |       3.6 |                  0.0 |
| D    |      0.9 |       0.0 |      42.0 | 2.89029872162462e-15 |
| E    |      0.2 |       0.3 |       0.9 |                  0.4 |
| F    |      0.8 |       0.1 |      13.1 | 7.28918857815741e-09 |
| G    |      2.0 |       0.3 |       7.1 | 8.38088163028732e-06 |
| H    |     -0.6 |       0.5 |      -1.1 |                  0.3 |
| J    |      0.6 |       0.6 |       1.1 |                  0.3 |
| K    |      1.2 |       0.5 |       2.4 |                  0.0 |
| N    |      0.5 |       0.1 |       5.6 | 8.38901196792198e-05 |

Note that the weights do matter - look at the difference when they are left out 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
lmod2 <- lm(A2 ~ A + B + C + D + E + F + G + H + J + K + N - 1,
           fpe)

lmod2 %>% tidy()
#+END_SRC

#+RESULTS:
| term | estimate | std.error | statistic |              p.value |
|------+----------+-----------+-----------+----------------------|
| A    |      1.1 |       0.0 |      30.5 | 1.76812290833848e-13 |
| B    |     -0.1 |       0.0 |      -4.8 |                  0.0 |
| C    |      0.3 |       0.1 |       4.5 |                  0.0 |
| D    |      0.9 |       0.0 |      52.0 | 1.80130937575726e-16 |
| E    |      0.7 |       0.3 |       2.3 |                  0.0 |
| F    |      0.8 |       0.1 |      15.4 | 9.74122083137977e-10 |
| G    |      2.2 |       0.2 |       9.8 | 2.31440504183119e-07 |
| H    |     -0.9 |       0.5 |      -1.8 |                  0.1 |
| J    |      0.1 |       0.6 |       0.2 |                  0.8 |
| K    |      0.5 |       0.5 |       1.1 |                  0.3 |
| N    |      0.6 |       0.1 |       6.1 | 3.66135131358541e-05 |

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
tibble("round" = c(letters[1:8], "j", "k", "n"),
       "absolute difference" = abs(coef(lmod) - coef(lmod2)))
#+END_SRC

#+RESULTS:
| round | absolute difference |
|-------+---------------------|
| a     |                 0.0 |
| b     |                 0.0 |
| c     |                 0.0 |
| d     |                 0.0 |
| e     |                 0.4 |
| f     |                 0.0 |
| g     |                 0.2 |
| h     |                 0.3 |
| j     |                 0.5 |
| k     |                 0.7 |
| n     |                 0.0 |

This causes substantial changes for some of the lesser candidates. 

There is one problem left, unrelated to weighting. Proportions are supposed to be between zero and one. We can impose an ad hoc fix by truncating the coefficients that violate this restriction either to 0 or 1 as appropriate. 

The offset function means that no coefficient will be fit which is the same as saying the coefficient will be 1. 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
lm(A2 ~ offset(A + G + K) + C + D + E + F + N - 1,
   fpe,
   weights = (1 / EI)) %>%
    tidy()
#+END_SRC

#+RESULTS:
| term | estimate | std.error | statistic |              p.value |
|------+----------+-----------+-----------+----------------------|
| C    |      0.2 |       0.1 |       4.1 |                  0.0 |
| D    |      1.0 |       0.0 |      41.6 | 4.04523592592162e-20 |
| E    |      0.4 |       0.2 |       1.7 |                  0.1 |
| F    |      0.7 |       0.1 |       9.2 | 2.08232910399788e-08 |
| N    |      0.6 |       0.1 |       5.1 |  6.9406557537893e-05 |

We see that: 

- Almost all of the voters for D initially voted for A
- Almost all of the voters for C initially voted for B
- The rest are different splits 

This analysis is somewhat crude and there are more sophisticated approaches. 

The pcls() function in the mgcv package of Wood provides a solution to the constrained least squares problem (which in this case requires that $0 \leq \hat{\beta_i} \leq 1$). 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
library(mgcv)

M <- list(w = (1 / fpe$EI),
          X = model.matrix(lmod),
          y = fpe$A2,
          Ain = rbind(diag(11), - diag(11)),
          C = matrix(0, 0, 0),
          array(0, 0),
          S = list(),
          off = NULL,
          p = rep(0.5, 11),
          bin = c(rep(0, 11), rep(-1, 11)))

A <- pcls(M)

names(A) <- colnames(model.matrix(lmod))

tibble("round" = c(letters[1:8], "j", "k", "n"),
       "coefficients" = round(A, 3))
#+END_SRC

#+RESULTS:
| round | coefficients |
|-------+--------------|
| a     |          1.0 |
| b     |          0.0 |
| c     |          0.2 |
| d     |          1.0 |
| e     |          0.4 |
| f     |          0.7 |
| g     |          1.0 |
| h     |          0.4 |
| j     |          0.0 |
| k     |          1.0 |
| n     |          0.6 |

The results are quite similar for the candidates C, D, E, and N who have substantial numbers of votes, but the coefficients for the small party candidates vary much more. 

In the examples where the form of the variance of epsilon is not completely known, we may model sigma using a smaller number of parameters. For example, 

$sd(\epsilon_i) = \gamma_0 + x_1^{\gamma_1}$

might seem reasonable for in a given situation. 

Consider, for example, the cars data from chapter 7:

#+BEGIN_SRC R :file plot.svg :results graphics file
lmod3 <- lm(dist ~ speed, cars)

plot(residuals(lmod3) ~ speed, cars)

cars %>% 
    ggplot(aes(x = speed, y = residuals(lmod3))) +
    geom_point()
#+END_SRC

#+RESULTS:
[[file:plot.svg]]

The plot reveals that the variation in the residuals increases with speed. 

One solution to this problem is to set the weights according to the above form and simultaneously estimate beta and gamma using maximum likelihood methods. 

#+BEGIN_SRC R :results output
wlmod <- gls(dist ~ speed,
             data = cars, 
             weights = varConstPower(1, form = ~ speed))

wlmod %>% summary()
#+END_SRC

#+RESULTS:
#+begin_example

Generalized least squares fit by REML
  Model: dist ~ speed 
  Data: cars 
       AIC      BIC    logLik
  412.8352 422.1912 -201.4176

Variance function:
 Structure: Constant plus power of variance covariate
 Formula: ~speed 
 Parameter estimates:
   const    power 
3.160444 1.022368 

Coefficients:
                 Value Std.Error   t-value p-value
(Intercept) -11.085378  4.052378 -2.735524  0.0087
speed         3.484162  0.320237 10.879947  0.0000

 Correlation: 
      (Intr)
speed -0.9  

Standardized residuals:
       Min         Q1        Med         Q3        Max 
-1.4520579 -0.6898209 -0.1308277  0.6375029  3.0757014 

Residual standard error: 0.7636833 
Degrees of freedom: 50 total; 48 residual
#+end_example

We see that $\gamma_0 = 3.16$ and $\hat{\gamma_1} = 1.022$. 

Since the latter is so close to 1, this variance function takes a simple form.  

** Testing for Lack of Fit 

How can we tell whether a model fits the data? 

If a model is correct, then our variance estimator should be an unbiased estimate of our actual variance. This suggests a testing procedure in which we compare our estimator to our actual variance. This is rather uncommon in practice, so we need some way to get an idea of what the actual variance is. 

We could make a comparison to some model free estimate of $\sigma^2$. We can do this if we have repeated values of the response for one or more fixed values of x. These replicates do need to be truly independent. For example, the cases in the data may be people and the response might be blood pressure. If we had different people but the same predictor values, we could get an idea of the between-subject variability and then we could construct an estimate of $sigma^2$ that does not depend on a particular model.

Let $y_{ij}$ be the ith observation in the group of true replicates j. The "pure error" or model-free estimate of $\sigma^2$ is given by 

**insert math eqns here for sspe and df **

There is a convenient way to compute the estimate. Fit a model that assigns one parameter to each group of observations with fixed x, then the variance estimator from this model will be the pure error. The model itself simply fits a mean to each group of estimates. Comparing this model to the regression model using the standard F-test gives us the lack-of-fit test. 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
data(corrosion, package = "faraway")
corrosion %<>% as_tibble()
#+END_SRC

#+BEGIN_SRC R :file plot.svg :results graphics file
corrosion %>%
    ggplot(aes(x = Fe, y = loss)) +
    geom_point() +
    labs(x = "Iron Content",
         y = "Weight Loss")
#+END_SRC

#+RESULTS:
[[file:plot.svg]]

Now we fit a straight line model 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
lmod <- lm(loss ~ Fe, corrosion)

lmod %>% glance()
#+END_SRC

#+RESULTS:
| r.squared | adj.r.squared | sigma | statistic |              p.value |  df | logLik |  AIC |  BIC | deviance | df.residual |
|-----------+---------------+-------+-----------+----------------------+-----+--------+------+------+----------+-------------|
|       1.0 |           1.0 |   3.1 |     352.3 | 1.05535526706818e-09 | 2.0 |  -31.9 | 69.8 | 71.5 |    102.9 |        11.0 |

We have an Rsq value of 97% and what looks like a good fit to the data. 


#+BEGIN_SRC R :file plot.svg :results graphics file
corrosion %>%
    ggplot(aes(x = Fe, y = loss)) +
    geom_point() +
    geom_abline(slope = lmod$coefficients[[2]],
                intercept = lmod$coefficients[[1]],
                lty = 2) +
    labs(x = "Iron Content",
         y = "Weight Loss") 
#+END_SRC

#+RESULTS:
[[file:plot.svg]]

We now fit a model that reserves a parameter for each group of data with the same value of x. This is accomplished by declaring the predictor to be a factor. 

#+BEGIN_SRC R :post round-tbl[:colnames yes](*this*)
lmoda <- lm(loss ~ factor(Fe), corrosion)

lmoda %>% tidy()
#+END_SRC

#+RESULTS:
| term           | estimate | std.error | statistic |              p.value |
|----------------+----------+-----------+-----------+----------------------|
| (Intercept)    |    128.6 |       0.8 |     158.9 |  4.1885655789357e-12 |
| factor(Fe)0.48 |     -5.6 |       1.3 |      -4.4 |                  0.0 |
| factor(Fe)0.71 |    -16.6 |       1.3 |     -13.0 | 1.28177759939805e-05 |
| factor(Fe)0.95 |    -24.7 |       1.6 |     -15.2 | 5.02984555927067e-06 |
| factor(Fe)1.19 |    -27.1 |       1.6 |     -16.7 | 2.91396797676478e-06 |
| factor(Fe)1.44 |    -36.7 |       1.3 |     -28.7 | 1.18433281242117e-07 |
| factor(Fe)1.96 |    -43.6 |       1.3 |     -34.1 | 4.23782401332901e-08 |

The fitted values are the means in each group and we can plot these. 

#+BEGIN_SRC R :file plot.svg :results graphics file
corrosion %>%
    ggplot(aes(x = Fe, y = loss)) +
    geom_point() +
    geom_point(data = augment(lmoda), aes(y = .fitted, x = corrosion$Fe),
               shape = 5, color = "blue") +
    labs(x = "Iron Content",
         y = "Weight Loss")
#+END_SRC

We can now compare the two models in the usual way: 

#+BEGIN_SRC R :results output
anova(lmod, lmoda)
#+END_SRC

#+RESULTS:
: Analysis of Variance Table
: 
: Model 1: loss ~ Fe
: Model 2: loss ~ factor(Fe)
:   Res.Df     RSS Df Sum of Sq      F   Pr(>F)   
: 1     11 102.850                                
: 2      6  11.782  5    91.069 9.2756 0.008623 **
: ---
: Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

The low p-value indicates that we must conclude there is a lack of fit. 
